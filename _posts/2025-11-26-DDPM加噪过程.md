---
title: DDPM加噪过程
date: 2025-11-26
categories:
  - Diffusion
tags:
  - DDPM
---
DDPM 原理：经典的 DDPM 是离散的，比如一共走 $N=1000$ 步。每一步 $i$ 的加噪公式是：
$$x_i = \sqrt{1 - \beta_i} x_{i-1} + \sqrt{\beta_i} \epsilon_{i-1}$$为什么要写成这么复杂的 $\sqrt{1-\beta_t}$ 和 $\sqrt{\beta_t}$，而不是直接写成 $x_{t-1} + \beta_t \epsilon$？

这里的核心设计哲学叫做 **“方差保全”（Variance Preserving）**。

简单来说：**为了保证图片在加了一千次噪声后，数值范围（能量）依然稳定，不会爆炸，也不会消失。**


假如我们要“混合”两样东西

把加噪过程想象成**调鸡尾酒**。

- $x_{t-1}$ 是原来的酒（信号）。
- $\epsilon$ 是水（噪声/高斯分布）。

如果我们只是往酒里不停倒水（$x_t = x_{t-1} + \epsilon$）：

- 杯子里的液体会越来越多。
- 在数学上，这意味着**方差（Variance）会越来越大**。
- 假设 $x_0$ 的方差是 1，加 1000 次噪声后，方差变成 1001。数值会变得非常巨大，神经网络很难处理这种数据。

### 必须做“加权平均”

为了让杯子里的液面高度保持不变（方差始终为 1），我们在倒水（加噪）的同时，必须**倒掉一点原来的酒**（衰减信号）。

我们要给信号和噪声各分配一个系数（权重）：

$$x_t = \text{系数}_1 \cdot x_{t-1} + \text{系数}_2 \cdot \epsilon$$

这两个系数必须满足一个数学条件：**平方和等于 1**。

为什么是平方和？

根据统计学定理（独立变量方差的可加性）：

$$\text{Var}(A + B) = \text{Var}(A) + \text{Var}(B)$$

如果 $X$ 被乘以一个系数 $a$，那么它的方差会被乘以 $a^2$（$\text{Var}(aX) = a^2 \text{Var}(X)$）。

假设我们希望 $x_{t-1}$ 和 $x_t$ 都是标准正态分布（方差为 1），且噪声 $\epsilon$ 方差也是 1：

$$\begin{aligned} \text{Var}(x_t) &= \text{系数}_1^2 \cdot \text{Var}(x_{t-1}) + \text{系数}_2^2 \cdot \text{Var}(\epsilon) \\ 1 &= \text{系数}_1^2 \cdot 1 + \text{系数}_2^2 \cdot 1 \end{aligned}$$

所以必须满足：$\text{系数}_1^2 + \text{系数}_2^2 = 1$。
我们定义 $\beta_t$ 为这一步添加的噪声的方差量。

也就是说，我们规定：

$$\text{系数}_2^2 = \beta_t$$

那么，噪声项前面的系数就是 $\sqrt{\beta_t}$。

为了保持总方差守恒（等于 1），信号项的系数平方必须是剩余的部分：

$$\text{系数}_1^2 = 1 - \beta_t$$

那么，信号项前面的系数就是 $\sqrt{1 - \beta_t}$。

于是就有了那个经典的公式：

$$x_t = \underbrace{\sqrt{1 - \beta_t}}_{\text{衰减旧信号}} x_{t-1} + \underbrace{\sqrt{\beta_t}}_{\text{添加新噪声}} \epsilon$$


