---
title: DDPM和SDE
date: 2025-11-26
categories:
  - Diffusion
tags:
  - DDPM
---
> **DDPM是diffusion SDE的一阶离散**

回想一下，我们在DDPM里的加噪过程。每一个time step，我们都会按照如下的离散马尔可夫链进行加噪：

$$x_i = \sqrt{1 - \beta_i} x_{i-1} + \sqrt{\beta_i} \epsilon_{i-1}$$

但是论文里面提到要将这个离散过程连续化变成SDE（随机微分方程）。
## 为什么我们要将离散的加噪过程连续化？

我们可以用**“走楼梯 vs. 滑滑梯”**来比喻。

- **离散 DDPM** 就像是修好的**楼梯**，规定了必须有 1000 级台阶。你只能一步一步走。
- **连续 SDE** 就像是一个平滑的**滑滑梯**（或者斜坡）。

以下是“滑滑梯”（连续化）带来的三大优势：

### 1. 训练与采样的“解耦” (Decoupling) —— 最大的实用价值

- 离散的痛点（DDPM）：
    在 DDPM 中，如果你训练时设定了 $N=1000$ 步，那么你在生成图片（推理/采样）时，通常也必须老老实实走完这 1000 步。如果你想快点，只走 50 步，效果通常会变差，或者需要重新训练一个 $N=50$ 的模型。
    - _训练和推理被绑死了。_

- 连续的优势（SDE）：
    一旦我们将模型建模为连续的 SDE，我们就学习到了这个物理过程的全貌（原本的函数曲线）。
    在生成图片时，我们可以自由决定怎么走：
    - 你可以用 **1000 步** 慢慢走，画质极度细腻。
    - 你可以用 **20 步** 大跨步走（离散化），快速出图。
    - **我们不需要重新训练模型**，只需要在采样时改变“步长”即可。这让扩散模型的实用性大大增强。
### 2. 可以借用几百年的数学工具 (Numerical Solvers)
- **离散的痛点**： DDPM 的反向采样公式是固定的，那是作者推导出来的特定公式。你只能用那个公式。
- **连续的优势**： 一旦变成微分方程（SDE/ODE），我们就进入了传统数学的“军火库”。人类研究如何解微分方程已经好几百年了（龙格-库塔法 Runge-Kutta, Euler 方法, Heun 方法等）。
    - 我们可以直接拿现成的、高精度的**数值求解器 (Black-box Solvers)** 来解这个方程。
    - 这就是为什么后来出现了像 DPM-Solver 这样的技术，能在 10-20 步内生成高质量图片，本质上就是用了更聪明的数学方法来解这个 SDE，而不是傻傻地一步步挪

### 3. 开启了“确定性采样”的大门 (Probability Flow ODE)

这是宋飏（Yang Song）论文中最惊艳的一点。
- **SDE 是随机的**：正常的 SDE 生成过程包含随机噪声 $dw$，每次生成的图都不一样。
- **ODE 是确定的**：宋飏证明了，每一个 SDE 都有一个对应的 **ODE（常微分方程）**，叫做 **Probability Flow ODE**。
    - 这个 ODE 的轨迹和 SDE 共享同样的边缘分布，但它是**完全确定**的（没有随机项）。
**这有什么用？**
- **图像编辑与反演 (Inversion)**：因为过程是确定的，我们可以把一张真实的图片，沿着 ODE 倒推回去变成噪声（编码），修改一下，再推回来（解码）。这在原来的随机 DDPM 里很难做到，因为随机噪声让你回不去原来的路。
- **平滑插值**：你可以在两个噪声之间做插值，生成的图片会像视频一样平滑过渡。


## **DDPM到SDE的推导**

### 首先引入一组辅助的noise scale
令 $\beta_i = \frac{\bar{\beta}_i}{N}$，我们保证了无论切分成多少步，$N \times \beta_i$（总体的噪声强度）大致保持不变，从而顺利地取极限得到连续函数 $\beta(t)$。
为什么引入这个noise scale？
1. 它可以让我们合法地把 **$x_{i} - x_{i-1}$** 这种写法，改写成 **$x(t) - x(t-\Delta t)$**。
2. 进而再改写成微分形式 **$dx$**。
一句话解释：
它告诉我们，连续函数 $\beta(t), x(t), \epsilon(t)$ 并不是凭空画出来的，而是由那无数个密密麻麻的离散点 $(i, x_i)$ 连起来组成的。 当点足够密（$N \to \infty$）时，折线就变成了曲线。

此处$\beta(t)$ 是加噪计划，$x(t)$ 是每次加噪之前充满噪点的图像, $\epsilon(t)$ 是噪声的强度
在求极限之前，我们需要先引入一组辅助的 noise scale $\{\bar{\beta}_i = N\beta_i\}_{i=1}^N$，并将上面的式子改写如下：

$$
x_i = \sqrt{1 - \frac{\bar{\beta}_i}{N}} x_{i-1} + \sqrt{\frac{\bar{\beta}_i}{N}} \epsilon_{i-1}, \quad i=1, \dots, N
$$

在 $N \to \infty$ 时，上面的 $\{\bar{\beta}_i\}_{i=1}^N$ 就成了一个关于时间 $t$ 的连续函数 $\beta(t)$，并且 $t \in [0, 1]$。随后，我们可以假设 $\Delta t = \frac{1}{N}$，在每个 $i\Delta t$ 时刻，连续函数 $\beta(t), x(t), \epsilon(t)$ 都等于之前的离散值，即：

$$
\beta\left(\frac{i}{N}\right) = \bar{\beta}_i, \quad x\left(\frac{i}{N}\right) = x_i, \quad \epsilon\left(\frac{i}{N}\right) = \epsilon_i
$$

### 接下来就是要往微分方程上靠
SDE 的标准长相是：

$$\mathrm{d}x = f(x,t)\mathrm{d}t + g(t)\mathrm{d}w$$

这里的 $\mathrm{d}x$ 意思是：在极短的时间内，x 变化了多少？
如果你想得到一个**微分方程**（即 $\mathrm{d}x = \dots$ 的形式），你必须先计算“下一步在哪里”，然后减去“现在在哪里”
也就是计算$x(t + \Delta t)$ 是为了凑出 **“变化量” ($\mathrm{d}x$)**
我们的最终目标是推导出 SDE（随机微分方程）。
之前离散状况下，i是在1-N。 现在连续了，改成t属于0-1了，
在 $t \in \{0, 1, \dots, \frac{N-1}{N}\}$ 以及 $\Delta t = \frac{1}{N}$ 的情况下，我们就可以用连续函数改写之前的式子： $$ \begin{aligned} x(t + \Delta t) &= \sqrt{1 - \beta(t + \Delta t)\Delta t} \, x(t) + \sqrt{\beta(t + \Delta t)\Delta t} \, \epsilon(t) \\ &\approx x(t) - \frac{1}{2}\beta(t + \Delta t)\Delta t \, x(t) + \sqrt{\beta(t + \Delta t)\Delta t} \, \epsilon(t) \\ &\approx x(t) - \frac{1}{2}\beta(t)\Delta t \, x(t) + \sqrt{\beta(t)\Delta t} \, \epsilon(t) \end{aligned} $$
上面的近似只有在 $\Delta t \ll 1$ 时成立。我们将其再移项后就可以得到下式： $$ \begin{aligned} x(t + \Delta t) - x(t) &\approx -\frac{1}{2}\beta(t)\Delta t \, x(t) + \sqrt{\beta(t)\Delta t} \, \epsilon(t) \\ \mathrm{d}x &= -\frac{1}{2}\beta(t)x \mathrm{d}t + \sqrt{\beta(t)} \mathrm{d}w \end{aligned} $$

### 第一行：翻译（从离散到连续记号）

$$x(t + \Delta t) = \sqrt{1 - \beta(t + \Delta t)\Delta t} \, x(t) + \sqrt{\beta(t + \Delta t)\Delta t} \, \epsilon(t)$$

- 这是什么？
    这就等于离散公式 $x_i = \sqrt{1 - \beta_i} x_{i-1} + \sqrt{\beta_i} \epsilon$ 的“连续版翻译”。
- **对应关系**：
    - $x_i \to x(t + \Delta t)$ （下一步的状态）
    - $x_{i-1} \to x(t)$ （当前状态）
    - $\beta_i \to \beta(t+\Delta t)\Delta t$ （这一步的噪声方差量）·

---
### 第二行：线性化（泰勒展开大法）

$$\approx x(t) - \frac{1}{2}\beta(t + \Delta t)\Delta t \, x(t) + \sqrt{\beta(t + \Delta t)\Delta t} \, \epsilon(t)$$

- 发生了什么？
    这里对第一项系数 $\sqrt{1 - \dots}$ 动了手术。
- 数学原理（泰勒级数）：
    当 $x$ 非常非常小的时候，我们有一个黄金近似公式：$$\sqrt{1 - x} \approx 1 - \frac{1}{2}x$$(你可以试一下：$\sqrt{0.98} = \sqrt{1-0.02} \approx 1 - 0.01 = 0.99$。计算器按出来是 0.9899... 非常接近)
- 应用在这里：
    我们将 $x = \beta(t+\Delta t)\Delta t$ 代入：
    $$\sqrt{1 - \beta(t+\Delta t)\Delta t} \approx 1 - \frac{1}{2}\beta(t+\Delta t)\Delta t$$
    
- 结果：
    原来的乘法 $x(t)$ 变成了两部分：
    1. $1 \cdot x(t) = x(t)$ （保留原样）
    2. $- \frac{1}{2}\dots x(t)$ （衰减的一小部分）
- **注意**：第二项（噪声项）带根号 $\sqrt{\beta \Delta t}$，这里先不动它。因为 $\sqrt{\Delta t}$ 是 $0.5$ 次方，不能用这个泰勒公式。
---

### 第三行：平滑化（忽略高阶微小量）

$$\approx x(t) - \frac{1}{2}\beta(t)\Delta t \, x(t) + \sqrt{\beta(t)\Delta t} \, \epsilon(t)$$

- 发生了什么？
    把所有的 $t + \Delta t$ 直接写成了 $t$。
- 为什么可以这么做？
    因为 $\beta(t)$ 是我们设计的一个连续光滑的函数（比如线性的，或者余弦的）。
    当时间间隔 $\Delta t$ 趋近于 0 时，“下一瞬间的 $\beta$” 和 “现在的 $\beta$” 几乎没区别。$$\beta(t + \Delta t) \approx \beta(t)$$
- 目的：
    把式子里的变量统一，全部变成 $t$ 时刻的变量，方便后续处理。
