主要分为正向过程和逆向过程，正向过程类似于编码，逆向过程类似于解码。

正向过程加噪声的过程必须加高斯噪声，因为后面运算需要高斯噪声的一些特性，而且噪声是越加越多的。因为一开始图像比较清晰，只需要少量噪声就能扰动，后来图像不清晰，需要加很多噪声才行。
首先，我们会随机生成一个服从高斯分布的噪声图片，然后一步一步的减少噪声直到生成预期图片。

## 正向过程


## 反向过程

就是贝叶斯公式，然后再上一个条件变量

![](../assets/2025-11-27-Diffusion再读/file-20251127154005884.png)对高斯分布进行乘除运算的结果仍然是高斯分布


想手推公式去看https://zhuanlan.zhihu.com/p/610505558


![](../assets/2025-11-27-Diffusion再读/file-20251127155249539.png)
这个是正向的过程

![](../assets/2025-11-27-Diffusion再读/file-20251127155320864.png)
这个上反向过程估计出来的$X_{t-1}$ 的高斯分布的均值和方差



训练我们需要有真实值和预测值，那么对于本例的真实值和预测值是什么呢？真实值是我们输入的图片，预测值是我们输出的图片吗？其实不是，这里我就不和大家卖关子了。对于本例来说，真实值和预测值都是噪声，我们同样拿下图为大家做个示范。


训练与采样的区别？

训练时搞一个噪声

采样好像是跟反向有关？


网络学习的实际上是符合标准高斯分布的Zt，所以我有点理解不了那还要网络学习什么，标准高斯分布不是已经知道了吗？
**条件生成（Conditional Generation）**：模型在生成数据时需要根据给定的条件来决定生成的内容
**非条件生成（Unconditional Generation）**：与之相对，非条件生成指的是模型在没有任何外部条件的情况下生成数据。模型只是简单地从其学习到的数据分布中采样，生成样本。这种生成方式不依赖于任何特定的输入条件。

在扩散模型中，每一步的输入是带有一定噪声的图像（从完全随机噪声开始逐步还原），网络的任务是从这个带噪声的图像中预测出当前步骤的噪声



与AI的对话：
1. 为什么DDPM不能减少步数？
	这在数学上是多峰分布的问题，因为如果你把一个噪声视作起始，然后要求一步生成图片，这就导致会有多种选择，模型不知道该怎么办。
2. DDPM 之所以慢，是因为它被建模为一个**随机漫步（Random Walk）**。
	DDIM 做了一个关键的改动：它把逆向过程变成了“确定性”的。在 DDIM 的公式中，它去掉了每一步注入的随机噪声（让方差 $\sigma = 0$）。这意味着，只要给定初始噪声 $x_T$，生成的轨迹就是**固定**的。
	所以DDIM可以把步子设置的更大一点
3. 扩散模型的训练本质上是一个**自监督（Self-Supervised）**的过程。我们不需要人工标注数据，只需要原图和一堆高斯噪声。
	想象我们是老师，模型是学生，我们在玩一个“找茬”游戏：

	**前向加噪（Forward Diffusion）**：
    - 我们拿一张高清图 $x_0$（比如一张猫）。
    - 随机选一个时间点 $t$（比如 $t=500$）。
    - 根据 $t$ 往图上叠加对应强度的标准高斯噪声 $\epsilon$，得到一张噪点图 $x_t$。
    - **关键点**：这步是纯数学计算，不需要神经网络，瞬间完成。
	**模型预测（Model Prediction）**：
    - 我们将这张噪点图 $x_t$ 丢给神经网络（通常是一个 **U-Net**）。
    - 我们要求网络回答一个问题：“请告诉我，这张图里具体包含了什么样的噪声？”
    - 网络的输出记为 $\epsilon_\theta(x_t, t)$。
	**计算损失（Loss Calculation）**：
	- 因为是我们自己加的噪声，我们手里有标准答案 $\epsilon$。
	- 我们直接对比**网络猜的噪声**和**真实添加的噪声**，计算它们之间的差距（通常用 MSE 均方误差）。
	- $Loss = ||\epsilon - \epsilon_\theta(x_t, t)||^2$
- 只要不断重复这个过程，网络最终就会变成一个**“噪声鉴赏大师”**：给它任何一张带噪的图，它都能精准地把里面的噪声成分提取出来。

4. 采样过程 (Sampling)：利用“噪声预测”来去噪
	训练好了这个“噪声鉴赏大师”（U-Net），我们就可以用它来生成图像了。这里就是 DDPM 和 DDIM 分道扬镳的地方。
	
	**共同的第一步**：随机生成一个纯噪声 $x_T$。
	**接下来是循环迭代（从 $T$ 到 $0$）：**
	把当前的图 $x_t$ 和时间 $t$ 喂给训练好的 U-Net。
    
	U-Net 预测出图里的噪声 $\epsilon_\theta$。
	**做减法（去噪）**：
	- **DDPM 的做法**：$x_{t-1} = \frac{1}{\sqrt{\alpha_t}} (x_t - \text{系数} \cdot \epsilon_\theta) + \sigma_t z$
        - 这里减去一部分预测的噪声，然后**必须**再加上一点点新的随机噪声 $z$（Langevin 动力学）。
    - **DDIM 的做法**：$x_{t-1} = \text{公式变种}(x_t, \epsilon_\theta)$
        - 它利用预测出的噪声，直接通过非马尔可夫链的公式指向 $x_{t-1}$，**不加**任何随机噪声。